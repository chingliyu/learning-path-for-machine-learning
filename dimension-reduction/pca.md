# Principal Component Analysis (PCA)

[Back to Index](../README.md)

---

## Objective

Learn PCA

## Prerequisite Reading

* Brush up  on [Unsupervised learning](../machine-learning/unsupervised.md)

## About Dimension Reduction

* [Understanding dimensionality reduction](https://machinelearningmastery.com/dimensionality-reduction-for-machine-learning/)
* [A beginner’s guide to dimensionality reduction in Machine Learning](https://towardsdatascience.com/dimensionality-reduction-for-machine-learning-80a46c2ebb7e)
* [A cool video explaining dim reduction](https://www.youtube.com/watch?v=jPmV3j1dAv4&ab_channel=SirajRaval) - must watch this video for the special effects and you too will become a fan of [Siraj Raval](https://www.youtube.com/channel/UCWN3xxRkmTPmbKwht9FuE5A)
* [Dimensionality Reduction](https://www.youtube.com/watch?v=3uxOyk-SczU&ab_channel=Udacity) - a good video intro

## PCA - Principal Component Analysis

* [Principal Component Analysis for Dimensionality Reduction in Python](https://machinelearningmastery.com/principal-components-analysis-for-dimensionality-reduction-in-python/) - good intro and code
* [Introduction To Principal Component Analysis In Machine Learning](https://www.analyticssteps.com/blogs/introduction-principal-component-analysis-machine-learning)
* [PCA using Python (scikit-learn)
](https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60)

## Extra Reading

### A Little Math

* [A very nice explainer video of Eigenvectors](https://www.youtube.com/watch?v=PFDu9oVAE-g&ab_channel=3Blue1Brown) from [3 Blue 1 Brown](https://www.youtube.com/c/3blue1brown) - I am fan !
* [Eigenvalues and Eigenvectors](https://textbooks.math.gatech.edu/ila/eigenvectors.html)

## Knowledge Check

* Why not use all dimensions for ML?
* What is the difference between feature selection and dimension reduction?
* What is the use case for PCA?
* What are `principal components (PC)`?
* What would be the trend of successive eigen values of PCs?
* What about `cummulative eigen values` of PCs?
* What does a correlation matrix of PCs look like?

## Exercises

### Difficulty Level

★☆☆  - Easy  
★★☆  - Medium  
★★★  - Challenging  
★★★★ - Bonus

### EX-1: Using PCA to visualize (★☆☆)

Start with this [pca-1-intro](https://github.com/elephantscale/guided-machine-learning-labs/blob/master/dim-reduction/pca-1-intro.ipynb) notebook.

Here we will reduce dimensions of a [mtcars dataset](https://s3.amazonaws.com/elephantscale-public/data/cars/mtcars.csv) to 2 dimensions so we can do a plot

### EX-2: PCA on wine quality data  (★★☆)


Start with this [pca-2-wine-quality](https://github.com/elephantscale/guided-machine-learning-labs/blob/master/dim-reduction/pca-2-wine-quality.ipynb) notebook.

We will perform PCA [wine quality data](https://elephantscale-public.s3.amazonaws.com/data/wine-quality/winequality-red.csv)

## More Exercises

---

## [Index](../README.md)
